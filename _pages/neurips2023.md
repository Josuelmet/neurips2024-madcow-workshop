---
layout: home
order: 1
permalink: /
title: Workshop 2024
# redirect_from: /index.html
desc_title: AI in the Synthetic Age @ NeurIPS 2024
description: <strong>The Synthetic Data Age is here to stay</strong> - Generative AI models are training on AI-generated data, whether knowingly or unknowingly. What does this mean for the future, and how do we handle it?
social: true
---

<!-- <td style="text-align:center"><img src="assets/img/workshop-votes.png" height="170"></td> <br />
<td style="text-align:center"><a href="https://bit.ly/bugs-orals">Vote Best Oral</a> | <a href="https://bit.ly/bugs-posters">Vote Best Poster</a></td> <br /> -->

Advances in generative artificial intelligence (AI) algorithms for imagery, text, and other data types have led to the temptation to use AI-synthesized data to train next-generation models.
Repeating this process creates a self-consuming loop whose properties are poorly understood.
This workshop seeks to gather new insights for three key aspects of self-consuming AI models:
<ol>
  <li>
    theoretical guarantees or empirical descriptions concerning the effects of self-consumption,
  </li>
  <li>
    strategies to train generative AI models on AI-generated data while avoiding model collapse, and
  </li>
  <li>
    identifying the ethical and societal impacts of self-consuming AI models.
  </li>
</ol>

<!-- **UPDATE**: fill out this form if you are interested in a post-workshop social: [https://forms.gle/XjeSVmyHnsp7EmLB6](https://forms.gle/XjeSVmyHnsp7EmLB6). -->

<!-- ### Schedule (Meeting Room 317A, 9 AM - 5 PM, July 29, 2023) -->
### Schedule

<!-- <p>‚≠ê <strong>Link to NeurIPS page: <a href="https://neurips.cc/virtual/2023/workshop/66550">https://neurips.cc/virtual/2023/workshop/66550</a></strong> ‚≠ê</p> -->
<p>ü§ñ <strong>Link to NeurIPS page: <a href="https://neurips.cc/">https://neurips.cc/virtual/2024/workshop/?????</a></strong> ü§ñ</p>


<table style="width: 100%">
  <colgroup>
    <col span="1" style="width: 18%;">
    <col span="1" style="width: 46%;">
    <col span="1" style="width: 36%;">
  </colgroup>
  <thead>
    <tr>
      <th style="text-align: left">Start Time (PDT/GMT-07:00, Vancouver)</th>
      <th style="text-align: left">Session</th>
      <th style="text-align: left">Speaker(s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">08:55 am</td>
      <td style="text-align: left">Opening Remarks</td>
      <td style="text-align: left">Organizers</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: left">09:00 am</td>
      <td style="text-align: left"><strong>Invited Talk 1:</strong> Title 1</td>
      <td style="text-align: left">Speaker 1</td>
    </tr>
    <tr>
      <td style="text-align: left">09:30 am</td>
      <td style="text-align: left"><strong>Invited Talk 2:</strong> Title 2</td>
      <td style="text-align: left">Speaker 2</td>
    </tr>
    <tr>
      <td style="text-align: left">10:00 am</td>
      <td style="text-align: left">Coffee Break</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: left">10:30 am</td>
      <td style="text-align: left"><strong>Invited Talk 3:</strong> Title 3</td>
      <td style="text-align: left">Speaker 3</td>
    </tr>
    <tr>
      <td style="text-align: left">11:00 am</td>
      <td style="text-align: left"><strong>Oral 1:</strong> Paper Title</td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">11:15 am</td>
      <td style="text-align: left"><strong>Invited Talk 4:</strong> Talk 4</td>
      <td style="text-align: left">Speaker 4</td>
    </tr>
    <tr>
      <td style="text-align: left">11:45 am</td>
      <td style="text-align: left">Lunch Break</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: left">01:00 pm</td>
      <td style="text-align: left"><strong>Oral 2:</strong> Paper Title</td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">01:15 pm</td>
      <td style="text-align: left"><strong>Oral 3:</strong> Paper Title</td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">01:30 pm</td>
      <td style="text-align: left"><strong>Invited talk 5:</strong> Talk 5</td>
      <td style="text-align: left">Speaker 5</td>
    </tr>
    <tr>
      <td style="text-align: left">02:00 pm</td>
      <td style="text-align: left"><strong>Invited talk 6:</strong> Talk 6</td>
      <td style="text-align: left">Speaker 6</td>
    </tr>
    <tr>
      <td style="text-align: left">02:30 pm</td>
      <td style="text-align: left">Coffee Break</td>
      <td style="text-align: left">&nbsp;</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: left">03:00 pm</td>
      <td style="text-align: left"><strong>Poster Session</strong></td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">03:45 pm</td>
      <td style="text-align: left"><strong>Oral 4:</strong> Paper Title</td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">04:00 pm</td>
      <td style="text-align: left"><strong>Oral 5:</strong> Paper Title</td>
      <td style="text-align: left">Paper Authors</td>
    </tr>
    <tr>
      <td style="text-align: left">04:15 pm</td>
      <td style="text-align: left"><strong>Invited Talk 7:</strong> Talk 7</td>
      <td style="text-align: left">Speaker 7</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: left">04:45 pm</td>
      <td style="text-align: left"><strong>Panel Discussion</strong></td>
      <td style="text-align: left">Moderator: John Doe</td>
    </tr>
    <tr>
      <td style="text-align: left">05:15 pm</td>
      <td style="text-align: left">Closing Remarks</td>
      <td style="text-align: left">Organizers</td>
    </tr>
  </tbody>
</table>


### Speakers

<table style="width:100%">
  <tbody><tr>
    <td style="text-align:center"><img src="assets/img/speaker-josue-casco-square.png" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-tom-goldstein-square.jpg" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-nicolas-papernot-square.jpg" height="170" width="170"></td>
    <!-- <td style="text-align:center"><img src="assets/img/speaker-florian-tramer-square.png" height="170" width="170"></td> -->
    <td style="text-align:center"><img src="assets/img/speaker-abeba-birhane-square.png" height="170" width="170"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://sites.google.com/rice.edu/josuecasco-rodriguez/home">Josue Casco-Rodriguez</a> <br> Rice University</td>
    <td style="text-align:center"><a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a> <br> University of Maryland</td>
    <td style="text-align:center"><a href="https://www.papernot.fr/">Nicolas Papernot</a> <br> University of Toronto</td>
    <!-- <td style="text-align:center"><a href="https://floriantramer.com/">Rohan Taori or Tatsunori B. Hashimoto</a> <br> Stanford University</td> -->
    <td style="text-align:center"><a href="https://abebabirhane.com/">Abeba Birhane</a> <br> Mozilla Foundation</td>
  </tr>
  <tr>
    <td style="text-align:center"><img src="assets/img/speaker-nate-gillman-square.jpg" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-elvis-dohmatob-square.jfif" height="170" width="170"></td>
    <!-- <td style="text-align:center"><img src="assets/img/speaker-scott-aaronson-square.jpg" height="170" width="170"></td> -->
    <td style="text-align:center"></td>
    <td style="text-align:center"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://cs.brown.edu/people/ngillman//">Nate Gillman</a> <br> Brown University</td>
    <td style="text-align:center"><a href="https://dohmatob.github.io/">Elvis Dohmatob</a> <br> FAIR</td>
    <!-- <td style="text-align:center"><a href="https://www.scottaaronson.com/">Scott Aaronson</a> <br> UT Austin, OpenAI	</td> -->
    <td style="text-align:center"></td>
    <td style="text-align:center"></td>
  </tr>
</tbody></table>



### Panelists


<table style="width:100%">
  <tr>
    <td style="text-align:center"><img src="assets/img/panelist-franziska-boenisch-square.png" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-bo-li-square.png" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-baoyuan-wu-square.png" height="170" width="170"></td>
    <td style="text-align:center"><img src="assets/img/speaker-ruoxi-jia-square.png" height="170" width="170"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://franziska-boenisch.de/">Franziska Boenisch</a> <br>Tenure-track Faculty, CISPA</td>
    <td style="text-align:center"><a href="https://aisecure.github.io/">Bo Li</a> <br> Associate Professor, UIUC</td>
    <td style="text-align:center"><a href="https://sites.google.com/site/baoyuanwu2015/">Baoyuan Wu</a> <br> Associate Professor, CUHK-Shenzhen</td>
    <td style="text-align:center"><a href="https://ruoxijia.info/">Ruoxi Jia</a> <br> Assistant Professor, Virginia Tech</td>
  </tr>
</table>

### Workshop Sponsors

We gratefully acknowledge the support from our Sponsors.

<table style="width:100%; border: none;">
<td style="text-align:center; border: none;"><a href="https://troj.ai/"><img src="assets/img/sponsor-troj-ai.png" height="55"></a></td>

<td style="text-align:center; border: none;"><a href="https://ml.umd.edu/"><img src="assets/img/sponsor-umd-cml.png" height="65"></a></td>

<td style="text-align:center; border: none;"><a href="https://www.google.org/"><img src="assets/img/sponsor-google.png" height="75"></a></td>
</table>


### Organizers 

<table style="width:100%">
  <tbody><tr>
    <td style="text-align:center"><img src="assets/img/org-richard-baraniuk-square.jpg" height="150" width="150"></td>
    <td style="text-align:center"><img src="assets/img/org-sina-alemohammad-square.jfif" height="150" width="150"></td>
    <td style="text-align:center"><img src="assets/img/org-julia-kempe-square.png" height="150" width="150"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://richb.rice.edu/">Richard G. Baraniuk</a> <br>Rice University, USA</td>
    <td style="text-align:center"><a href="https://www.linkedin.com/in/sina-alemohammad-837b0ab6/">Sina Alemohammad</a> <br>Rice University, USA</td>
    <td style="text-align:center"><a href="https://cims.nyu.edu/~kempe/">Julia Kempe</a> <br>New York University, USA</td>
  </tr>
  <tr>
    <td style="text-align:center"><img src="assets/img/org-ilia-shumailov-square.jpg" height="150" width="150"></td>
    <td style="text-align:center"><img src="assets/img/org-tshilidzi-marwala-square.png" height="150" width="150"></td>
    <td style="text-align:center"><img src="assets/img/org-jathan-sadowski-square.png" height="150" width="150"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="https://x.com/iliaishacked">Ilia Shumailov</a> <br>DeepMind, UK</td>
    <td style="text-align:center"><a href="https://en.wikipedia.org/wiki/Tshilidzi_Marwala">Tshilidzi Marwala</a> <br>United Nations University, Japan</td>
    <td style="text-align:center"><a href="https://www.jathansadowski.com/">Jathan Sadowski</a> <br>Monash University, Australia</td>
  </tr>
</tbody></table>

### Organizers affiliations

<table style="width:100%; align: left; border: none; spacing: none">
  <tbody><tr style="border: none; spacing: none"> 
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/inst-rice.png" height="40"></a></td>
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/inst-nyu.jpg" height="40"></a></td>  
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/inst-unu.png" height="40"></a></td>
  </tr>
</tbody></table>
<table style="width:100%; align: left; border: none; spacing: none">
  <tbody><tr> 
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/sponsor-google.png" height="40"></a></td>
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/inst-deepmind.png" height="40"></a></td>
    <td style="text-align:center; border: none; spacing: none"><img src="assets/img/inst-monash.png" height="40"></a></td>
  </tr>
</tbody></table>

### Call for Papers


We cordially invite submissions and participation in our ‚ÄúBackdoors in Deep Learning: The Good, the Bad, and the Ugly‚Äù workshop (neurips2023-bugs.github.io) that will be held on December 15 or 16, 2023 at NeurIPS 2023, New Orleans, USA. 

The submission deadline is **<s>September 29, 2023</s> October 6th, 2023, 23:59 AoE** and the submission link <a href="https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/BUGS">https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/BUGS</a>.

#### Motivation and Topics

<!-- Deep neural networks (DNNs) are revolutionizing almost all AI domains and have become the core of many modern AI systems. Despite their superior performance compared to classical methods, DNNs also face new security problems, such as adversarial and backdoor attacks, that are hard to discover and resolve due to their black-box-like property. Backdoor attacks are possible because of insecure model pretraining and outsourcing practices. Due to the complexity and the tremendous cost of collecting data and training models, many individuals/companies employ models or training data from third parties. Malicious third parties can add backdoors into their models or poison their released data before delivering it to the victims to gain illegal benefits. This threat seriously damages the safety and trustworthiness of AI development.

While most works consider backdoors ‚Äúevil‚Äù, some studies leverage them for good purposes. A popular approach is to use the backdoor as a watermark to detect illegal uses of commercialized data/models. Watermarks can also be used to mark generated data, which becomes crucial with the introduction of big generative models (LLMs, text-to-image generators). For instance, the paper ‚ÄúA Watermark for Large Language Models‚Äù has received an outstanding paper award at ICML 2023, showing the community‚Äôs great interest in this critical topic. Besides, a few works employ the backdoor as a trapdoor for adversarial defense. Learning the underlying working mechanisms of backdoors also elevates our understanding of how deep learning models work.
This workshop is designed to provide a comprehensive understanding of the current state of backdoor research. Our goal is to foster discussion and perspective exchange, as well as to engage the community in identifying social good applications of backdoors. As such, we welcome submissions related to any aspect of backdoor research, including but not limited to: -->



We welcome submissions related to any aspect of backdoor research, including but not limited to: 

* Backdoor attacks
  * Poisoning attacks
  * Dirty-label backdoor attacks
  * Clean-label backdoor attacks
  * Backdoors in various learning paradigms (supervised, semi-supervised, self-supervised)
  * Backdoors in various computer vision tasks (object detection, segmentation)
  * Backdoors in multimodal models (vision+language)
  * Backdoors in federated learning
  * Backdoors in NLP and less-studied domains (speech, graphs)
  * Backdoors in generative models (e.g., Diffusion models)
  * Backdoors in Large Language Models
* Backdoor defenses
  * Backdoor detection (poisoned inputs, poisoned models) - Backdoor mitigation (data sanitization, model repair)
  * Understanding backdoor behaviors
* Backdoor for social good
  * Watermarking (for IP Protection, Ownership Verification, Generative Data Marking, etc...)
  * Trapdoor/Honeypot defenses
  * Model unlearning
  * Deep model behavior understanding

The workshop will employ a double-blind review process. Each submission will be evaluated based on the following criteria:

* Soundness of the methodology
* Relevance to the workshop
* Societal impacts

We only consider submissions that haven‚Äôt been published in any peer-reviewed venue, including NeurIPS 2023 conference. **We allow dual submissions with other workshops or conferences. The workshop is non-archival and will not have any official proceedings**. All accepted papers will be allocated either a poster presentation or a talk slot.
 
<!-- ### Call for Reviewers
Please fill out this [Google form](https://docs.google.com/forms/d/e/1FAIpQLSd3L9_o7vAZUSWjWMxi18jZHuIrBaafUBm6v1fTZQorK2o9Qw/viewform) if you are interested in reviewing for the workshop.

üèÜ **2 free ICML 2023 workshop registrations will be given as "Best Reviewer Awards"** üèÜ -->

### Important Dates

* **Submission deadline**: <s>September 29th, 2023</s> October 6th, 2023, 11:59 PM Anywhere on Earth (AoE)
* **Author notification**: October 27th, 2023
* **Camera-ready deadline**: December 1st, 2023, 11:59 PM Anywhere on Earth (AoE)
* **Workshop date**: December 15th, 2023 (Full-day Event)

### Submission Instructions

Papers should be submitted to OpenReview: <a href="https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/BUGS">https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/BUGS</a>

Submitted papers should have up to 6 pages (excluding references, acknowledgments, or appendices). Please use the NeurIPS submission template provided at <a href="https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles">https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles</a>.
Submissions must be anonymous following NeurIPS double-blind reviewing guidelines, NeurIPS Code of Conduct, and Code of Ethics. Accepted papers will be hosted on the workshop website but are considered non-archival and can be submitted to other workshops, conferences, or journals if their submission policy allows.


<!-- **Submission website: [OpenReview](https://openreview.net/group?id=ICML.cc/2023/Workshop/NCW)**

We solicit short workshop paper submissions of up to 4 pages + unlimited references/appendices. Please format submissions in ICML style. Submissions will be double blind: reviewers cannot see author names when conducting reviews, and authors cannot see reviewer names.

Some accepted papers will be accepted as contributed talks. All accepted posters are expected to be presented in-person at the poster session, and all papers published via Openreview after the workshop.

This workshop will not have formal proceedings, so we welcome the submission of work currently under review at other archival ML venues. We also welcome the submission of work recently published in information theory venues (e.g. Transactions on Information Theory, ISIT, ITW) that may be of interest to an ML audience. However, we will not consider work recently published in or accepted to other archival ML venues (e.g. ICML main conference). -->
